{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuters newswire topics classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總共有11228筆資料，要分成46類，資料來源為keras.datasets裡的reuters資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 1200 \n",
    "batch_size = 8\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輸入變數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 2, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      " [1, 2, 699, 2, 2, 56, 2, 2, 9, 56, 2, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 2, 7, 2, 49, 2, 2, 1037, 2, 699, 2, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2, 2, 2, 775, 7, 48, 34, 191, 44, 35, 2, 505, 17, 12]\n",
      " [1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 2, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 1013, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 2, 55, 2, 92, 617, 80, 2, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 1118, 7, 2, 81, 5, 187, 11, 15, 9, 2, 201, 5, 47, 2, 18, 478, 2, 5, 1118, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12]\n",
      " ...,\n",
      " [1, 141, 2, 387, 81, 8, 16, 2, 10, 340, 2, 850, 31, 56, 2, 691, 9, 2, 71, 9, 2, 2, 2, 699, 2, 2, 2, 699, 244, 2, 4, 49, 8, 4, 656, 850, 33, 2, 9, 2, 340, 2, 2, 9, 2, 22, 2, 1094, 687, 83, 35, 15, 257, 6, 57, 2, 7, 4, 2, 654, 5, 2, 2, 2, 4, 49, 8, 16, 369, 646, 6, 1076, 7, 124, 407, 17, 12]\n",
      " [1, 53, 46, 957, 26, 14, 74, 132, 26, 39, 46, 258, 2, 18, 14, 74, 134, 2, 18, 88, 2, 72, 11, 14, 2, 32, 11, 123, 383, 89, 39, 46, 235, 10, 864, 728, 5, 258, 44, 11, 15, 22, 753, 9, 42, 92, 131, 728, 5, 69, 312, 11, 15, 22, 222, 2, 2, 383, 48, 39, 74, 235, 10, 864, 276, 5, 61, 32, 11, 15, 21, 4, 211, 5, 126, 1072, 42, 92, 131, 46, 19, 352, 11, 15, 22, 710, 220, 9, 42, 92, 131, 276, 5, 59, 61, 11, 15, 22, 10, 455, 7, 1172, 137, 336, 2, 6, 2, 142, 971, 2, 43, 359, 5, 4, 326, 753, 364, 17, 12]\n",
      " [1, 227, 2, 91, 2, 125, 2, 21, 4, 2, 76, 7, 4, 757, 481, 2, 790, 2, 2, 9, 111, 149, 8, 7, 10, 76, 223, 51, 4, 417, 8, 1047, 91, 2, 2, 340, 7, 194, 2, 6, 2, 21, 127, 2, 2, 2, 6, 2, 4, 329, 433, 7, 65, 87, 1127, 10, 2, 2, 290, 9, 21, 567, 16, 2, 24, 4, 76, 209, 30, 2, 2, 2, 8, 4, 60, 8, 4, 966, 308, 40, 2, 129, 2, 295, 277, 1071, 9, 24, 286, 2, 234, 222, 9, 4, 906, 2, 2, 114, 2, 2, 7, 4, 113, 17, 12]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標變數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  4  3 ..., 25  3 25]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練資料集有8982筆，測試資料集有2246筆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982 train sequences\n",
      "2246 test sequences\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標要分成46類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 classes\n"
     ]
    }
   ],
   "source": [
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizer的方法轉成詞向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing sequence data...\n",
      "x_train shape: (8982, 1200)\n",
      "x_test shape: (2246, 1200)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorizing sequence data...')\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (8982, 46)\n",
      "y_test shape: (2246, 46)\n"
     ]
    }
   ],
   "source": [
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實驗1： 比較隱藏層內節點數量和準確度的關係"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  比較的節點數分別為64、128、256、512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 hidden layer 64 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0125 - acc: 0.5426 - val_loss: -0.0154 - val_acc: 0.7030\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0158 - acc: 0.7162 - val_loss: -0.0163 - val_acc: 0.7508\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0166 - acc: 0.7627 - val_loss: -0.0167 - val_acc: 0.7631\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0172 - acc: 0.7847 - val_loss: -0.0170 - val_acc: 0.7775\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0175 - acc: 0.7996 - val_loss: -0.0171 - val_acc: 0.7786\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0178 - acc: 0.8128 - val_loss: -0.0173 - val_acc: 0.7920\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0181 - acc: 0.8261 - val_loss: -0.0175 - val_acc: 0.8042\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0183 - acc: 0.8379 - val_loss: -0.0176 - val_acc: 0.8020\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0184 - acc: 0.8433 - val_loss: -0.0177 - val_acc: 0.8020\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0186 - acc: 0.8534 - val_loss: -0.0177 - val_acc: 0.8053\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0188 - acc: 0.8591 - val_loss: -0.0178 - val_acc: 0.8076\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0189 - acc: 0.8639 - val_loss: -0.0178 - val_acc: 0.8020\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0190 - acc: 0.8695 - val_loss: -0.0179 - val_acc: 0.8087\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0191 - acc: 0.8768 - val_loss: -0.0179 - val_acc: 0.8120\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0191 - acc: 0.8790 - val_loss: -0.0179 - val_acc: 0.8087\n"
     ]
    }
   ],
   "source": [
    "#Building model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='cosine_proximity',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/2246 [===================>..........] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: -0.0178238724558\n",
      "Test accuracy: 0.805431878949\n"
     ]
    }
   ],
   "source": [
    "accuracy64=score[1]\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 hidden layer 128 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0135 - acc: 0.5998 - val_loss: -0.0160 - val_acc: 0.7319\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0165 - acc: 0.7495 - val_loss: -0.0168 - val_acc: 0.7653\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0173 - acc: 0.7892 - val_loss: -0.0171 - val_acc: 0.7798\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0178 - acc: 0.8118 - val_loss: -0.0173 - val_acc: 0.7853\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0182 - acc: 0.8346 - val_loss: -0.0175 - val_acc: 0.7887\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0186 - acc: 0.8518 - val_loss: -0.0177 - val_acc: 0.8020\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0188 - acc: 0.8583 - val_loss: -0.0178 - val_acc: 0.8031\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0190 - acc: 0.8729 - val_loss: -0.0179 - val_acc: 0.8020\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0192 - acc: 0.8840 - val_loss: -0.0180 - val_acc: 0.8209\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0194 - acc: 0.8921 - val_loss: -0.0179 - val_acc: 0.8076\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0195 - acc: 0.8976 - val_loss: -0.0181 - val_acc: 0.8198\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0197 - acc: 0.9065 - val_loss: -0.0182 - val_acc: 0.8276\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0198 - acc: 0.9089 - val_loss: -0.0181 - val_acc: 0.8187\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0199 - acc: 0.9146 - val_loss: -0.0182 - val_acc: 0.8276\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 1s - loss: -0.0200 - acc: 0.9195 - val_loss: -0.0183 - val_acc: 0.8287\n"
     ]
    }
   ],
   "source": [
    "#Building model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='cosine_proximity',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2088/2246 [==========================>...] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: -0.0179436356601\n",
      "Test accuracy: 0.813000890525\n"
     ]
    }
   ],
   "source": [
    "accuracy128=score[1]\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 hidden layer 256 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 7s - loss: -0.0144 - acc: 0.6397 - val_loss: -0.0165 - val_acc: 0.7508\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 7s - loss: -0.0170 - acc: 0.7747 - val_loss: -0.0171 - val_acc: 0.7742\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 7s - loss: -0.0179 - acc: 0.8128 - val_loss: -0.0174 - val_acc: 0.7953\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 7s - loss: -0.0184 - acc: 0.8373 - val_loss: -0.0177 - val_acc: 0.7998\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 7s - loss: -0.0188 - acc: 0.8597 - val_loss: -0.0178 - val_acc: 0.8031\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 7s - loss: -0.0191 - acc: 0.8773 - val_loss: -0.0180 - val_acc: 0.8142\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 7s - loss: -0.0194 - acc: 0.8906 - val_loss: -0.0179 - val_acc: 0.8098\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 7s - loss: -0.0196 - acc: 0.9012 - val_loss: -0.0181 - val_acc: 0.8131\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 7s - loss: -0.0198 - acc: 0.9076 - val_loss: -0.0180 - val_acc: 0.8076\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 7s - loss: -0.0199 - acc: 0.9125 - val_loss: -0.0182 - val_acc: 0.8154\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 7s - loss: -0.0200 - acc: 0.9197 - val_loss: -0.0182 - val_acc: 0.8231\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 7s - loss: -0.0201 - acc: 0.9228 - val_loss: -0.0182 - val_acc: 0.8287\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 7s - loss: -0.0202 - acc: 0.9271 - val_loss: -0.0182 - val_acc: 0.8276\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 7s - loss: -0.0202 - acc: 0.9305 - val_loss: -0.0182 - val_acc: 0.8265\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 7s - loss: -0.0203 - acc: 0.9331 - val_loss: -0.0183 - val_acc: 0.8265\n"
     ]
    }
   ],
   "source": [
    "#Building model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='cosine_proximity',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056/2246 [==========================>...] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: -0.0179369744487\n",
      "Test accuracy: 0.808103294799\n"
     ]
    }
   ],
   "source": [
    "accuracy256=score[1]\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 hidden layer 512 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/15\n",
      "8083/8083 [==============================] - 15s - loss: -0.0149 - acc: 0.6675 - val_loss: -0.0165 - val_acc: 0.7464\n",
      "Epoch 2/15\n",
      "8083/8083 [==============================] - 15s - loss: -0.0174 - acc: 0.7880 - val_loss: -0.0171 - val_acc: 0.7731\n",
      "Epoch 3/15\n",
      "8083/8083 [==============================] - 15s - loss: -0.0181 - acc: 0.8268 - val_loss: -0.0175 - val_acc: 0.7898\n",
      "Epoch 4/15\n",
      "8083/8083 [==============================] - 15s - loss: -0.0188 - acc: 0.8571 - val_loss: -0.0177 - val_acc: 0.7976\n",
      "Epoch 5/15\n",
      "8083/8083 [==============================] - 15s - loss: -0.0192 - acc: 0.8769 - val_loss: -0.0178 - val_acc: 0.8065\n",
      "Epoch 6/15\n",
      "8083/8083 [==============================] - 15s - loss: -0.0194 - acc: 0.8905 - val_loss: -0.0180 - val_acc: 0.8120\n",
      "Epoch 7/15\n",
      "8083/8083 [==============================] - 15s - loss: -0.0197 - acc: 0.9025 - val_loss: -0.0181 - val_acc: 0.8154\n",
      "Epoch 8/15\n",
      "8083/8083 [==============================] - 15s - loss: -0.0199 - acc: 0.9124 - val_loss: -0.0180 - val_acc: 0.8109\n",
      "Epoch 9/15\n",
      "8083/8083 [==============================] - 15s - loss: -0.0200 - acc: 0.9200 - val_loss: -0.0181 - val_acc: 0.8154\n",
      "Epoch 10/15\n",
      "8083/8083 [==============================] - 15s - loss: -0.0201 - acc: 0.9227 - val_loss: -0.0180 - val_acc: 0.8165\n",
      "Epoch 11/15\n",
      "8083/8083 [==============================] - 15s - loss: -0.0202 - acc: 0.9282 - val_loss: -0.0181 - val_acc: 0.8154\n",
      "Epoch 12/15\n",
      "8083/8083 [==============================] - 15s - loss: -0.0203 - acc: 0.9317 - val_loss: -0.0180 - val_acc: 0.8165\n",
      "Epoch 13/15\n",
      "8083/8083 [==============================] - 15s - loss: -0.0203 - acc: 0.9339 - val_loss: -0.0181 - val_acc: 0.8187\n",
      "Epoch 14/15\n",
      "8083/8083 [==============================] - 15s - loss: -0.0204 - acc: 0.9358 - val_loss: -0.0180 - val_acc: 0.8142\n",
      "Epoch 15/15\n",
      "8083/8083 [==============================] - 15s - loss: -0.0204 - acc: 0.9386 - val_loss: -0.0180 - val_acc: 0.8120\n"
     ]
    }
   ],
   "source": [
    "#Building model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='cosine_proximity',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2112/2246 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: -0.0177351856681\n",
      "Test accuracy: 0.803650934996\n"
     ]
    }
   ],
   "source": [
    "accuracy512=score[1]\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "隱藏層有64節點，準確率為:    0.805431878949\n",
      "隱藏層有128節點，準確率為:   0.813000890525\n",
      "隱藏層有256節點，準確率為：  0.808103294799\n",
      "隱藏層有512節點，準確率為：  0.803650934996\n"
     ]
    }
   ],
   "source": [
    "print('隱藏層有64節點，準確率為:   ',accuracy64)\n",
    "print('隱藏層有128節點，準確率為:  ',accuracy128)\n",
    "print('隱藏層有256節點，準確率為： ',accuracy256)\n",
    "print('隱藏層有512節點，準確率為： ',accuracy512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實驗2： 比較epochs的次數和準確率的關係"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分別比較epochs 為15、30、45、60、75時準確度的差異"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epochs為30次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/30\n",
      "8083/8083 [==============================] - 2s - loss: -0.0136 - acc: 0.6024 - val_loss: -0.0160 - val_acc: 0.7319\n",
      "Epoch 2/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0165 - acc: 0.7531 - val_loss: -0.0168 - val_acc: 0.7697\n",
      "Epoch 3/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0174 - acc: 0.7939 - val_loss: -0.0171 - val_acc: 0.7809\n",
      "Epoch 4/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0179 - acc: 0.8165 - val_loss: -0.0174 - val_acc: 0.7942\n",
      "Epoch 5/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0183 - acc: 0.8356 - val_loss: -0.0176 - val_acc: 0.7998\n",
      "Epoch 6/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0186 - acc: 0.8499 - val_loss: -0.0177 - val_acc: 0.7976\n",
      "Epoch 7/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0188 - acc: 0.8602 - val_loss: -0.0178 - val_acc: 0.8131\n",
      "Epoch 8/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0191 - acc: 0.8749 - val_loss: -0.0179 - val_acc: 0.8053\n",
      "Epoch 9/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0192 - acc: 0.8841 - val_loss: -0.0180 - val_acc: 0.8154\n",
      "Epoch 10/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0194 - acc: 0.8932 - val_loss: -0.0181 - val_acc: 0.8198\n",
      "Epoch 11/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0196 - acc: 0.8992 - val_loss: -0.0181 - val_acc: 0.8220\n",
      "Epoch 12/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0197 - acc: 0.9052 - val_loss: -0.0181 - val_acc: 0.8242\n",
      "Epoch 13/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0198 - acc: 0.9094 - val_loss: -0.0182 - val_acc: 0.8287\n",
      "Epoch 14/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0198 - acc: 0.9129 - val_loss: -0.0183 - val_acc: 0.8343\n",
      "Epoch 15/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0199 - acc: 0.9155 - val_loss: -0.0182 - val_acc: 0.8287\n",
      "Epoch 16/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0200 - acc: 0.9190 - val_loss: -0.0183 - val_acc: 0.8265\n",
      "Epoch 17/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0200 - acc: 0.9216 - val_loss: -0.0183 - val_acc: 0.8242\n",
      "Epoch 18/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0201 - acc: 0.9237 - val_loss: -0.0183 - val_acc: 0.8276\n",
      "Epoch 19/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0202 - acc: 0.9279 - val_loss: -0.0183 - val_acc: 0.8287\n",
      "Epoch 20/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0202 - acc: 0.9297 - val_loss: -0.0183 - val_acc: 0.8298\n",
      "Epoch 21/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0202 - acc: 0.9307 - val_loss: -0.0183 - val_acc: 0.8276\n",
      "Epoch 22/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0203 - acc: 0.9323 - val_loss: -0.0182 - val_acc: 0.8176\n",
      "Epoch 23/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0203 - acc: 0.9347 - val_loss: -0.0182 - val_acc: 0.8220\n",
      "Epoch 24/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0203 - acc: 0.9348 - val_loss: -0.0182 - val_acc: 0.8209\n",
      "Epoch 25/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0204 - acc: 0.9379 - val_loss: -0.0181 - val_acc: 0.8154\n",
      "Epoch 26/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0204 - acc: 0.9385 - val_loss: -0.0182 - val_acc: 0.8242\n",
      "Epoch 27/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0204 - acc: 0.9368 - val_loss: -0.0183 - val_acc: 0.8309\n",
      "Epoch 28/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0204 - acc: 0.9405 - val_loss: -0.0183 - val_acc: 0.8254\n",
      "Epoch 29/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0205 - acc: 0.9421 - val_loss: -0.0182 - val_acc: 0.8265\n",
      "Epoch 30/30\n",
      "8083/8083 [==============================] - 1s - loss: -0.0205 - acc: 0.9417 - val_loss: -0.0182 - val_acc: 0.8220\n",
      "1968/2246 [=========================>....] - ETA: 0sTest score: -0.0179570290821\n",
      "Test accuracy: 0.8134461265\n"
     ]
    }
   ],
   "source": [
    "#Building model\n",
    "epochs=30\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='cosine_proximity',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "accuracy_epoch30=score[1]\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epoch為45次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/45\n",
      "8083/8083 [==============================] - 2s - loss: -0.0137 - acc: 0.6070 - val_loss: -0.0160 - val_acc: 0.7253\n",
      "Epoch 2/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0165 - acc: 0.7513 - val_loss: -0.0168 - val_acc: 0.7664\n",
      "Epoch 3/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0174 - acc: 0.7956 - val_loss: -0.0171 - val_acc: 0.7775\n",
      "Epoch 4/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0178 - acc: 0.8148 - val_loss: -0.0174 - val_acc: 0.7942\n",
      "Epoch 5/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0182 - acc: 0.8340 - val_loss: -0.0176 - val_acc: 0.7998\n",
      "Epoch 6/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0185 - acc: 0.8440 - val_loss: -0.0177 - val_acc: 0.8020\n",
      "Epoch 7/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0188 - acc: 0.8627 - val_loss: -0.0179 - val_acc: 0.8098\n",
      "Epoch 8/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0191 - acc: 0.8736 - val_loss: -0.0179 - val_acc: 0.8087\n",
      "Epoch 9/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0192 - acc: 0.8830 - val_loss: -0.0180 - val_acc: 0.8109\n",
      "Epoch 10/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0194 - acc: 0.8896 - val_loss: -0.0180 - val_acc: 0.8209\n",
      "Epoch 11/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0196 - acc: 0.9000 - val_loss: -0.0180 - val_acc: 0.8109\n",
      "Epoch 12/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0197 - acc: 0.9030 - val_loss: -0.0181 - val_acc: 0.8198\n",
      "Epoch 13/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0198 - acc: 0.9080 - val_loss: -0.0181 - val_acc: 0.8198\n",
      "Epoch 14/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0199 - acc: 0.9149 - val_loss: -0.0182 - val_acc: 0.8287\n",
      "Epoch 15/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0199 - acc: 0.9179 - val_loss: -0.0181 - val_acc: 0.8254\n",
      "Epoch 16/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0200 - acc: 0.9200 - val_loss: -0.0181 - val_acc: 0.8142\n",
      "Epoch 17/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0200 - acc: 0.9206 - val_loss: -0.0182 - val_acc: 0.8165\n",
      "Epoch 18/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0201 - acc: 0.9249 - val_loss: -0.0181 - val_acc: 0.8198\n",
      "Epoch 19/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0202 - acc: 0.9308 - val_loss: -0.0182 - val_acc: 0.8231\n",
      "Epoch 20/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0202 - acc: 0.9308 - val_loss: -0.0182 - val_acc: 0.8265\n",
      "Epoch 21/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0203 - acc: 0.9320 - val_loss: -0.0182 - val_acc: 0.8265\n",
      "Epoch 22/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0203 - acc: 0.9331 - val_loss: -0.0182 - val_acc: 0.8242\n",
      "Epoch 23/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0203 - acc: 0.9350 - val_loss: -0.0182 - val_acc: 0.8231\n",
      "Epoch 24/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0204 - acc: 0.9380 - val_loss: -0.0182 - val_acc: 0.8198\n",
      "Epoch 25/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0204 - acc: 0.9380 - val_loss: -0.0182 - val_acc: 0.8242\n",
      "Epoch 26/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0204 - acc: 0.9385 - val_loss: -0.0181 - val_acc: 0.8176\n",
      "Epoch 27/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0204 - acc: 0.9398 - val_loss: -0.0182 - val_acc: 0.8176\n",
      "Epoch 28/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0204 - acc: 0.9393 - val_loss: -0.0181 - val_acc: 0.8142\n",
      "Epoch 29/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0205 - acc: 0.9415 - val_loss: -0.0182 - val_acc: 0.8220\n",
      "Epoch 30/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0205 - acc: 0.9412 - val_loss: -0.0182 - val_acc: 0.8254\n",
      "Epoch 31/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0205 - acc: 0.9432 - val_loss: -0.0182 - val_acc: 0.8231\n",
      "Epoch 32/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0205 - acc: 0.9442 - val_loss: -0.0181 - val_acc: 0.8209\n",
      "Epoch 33/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9456 - val_loss: -0.0181 - val_acc: 0.8198\n",
      "Epoch 34/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0205 - acc: 0.9430 - val_loss: -0.0181 - val_acc: 0.8209\n",
      "Epoch 35/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9456 - val_loss: -0.0182 - val_acc: 0.8242\n",
      "Epoch 36/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9463 - val_loss: -0.0181 - val_acc: 0.8209\n",
      "Epoch 37/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9466 - val_loss: -0.0181 - val_acc: 0.8231\n",
      "Epoch 38/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9478 - val_loss: -0.0181 - val_acc: 0.8198\n",
      "Epoch 39/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9467 - val_loss: -0.0181 - val_acc: 0.8198\n",
      "Epoch 40/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9475 - val_loss: -0.0181 - val_acc: 0.8131\n",
      "Epoch 41/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9464 - val_loss: -0.0181 - val_acc: 0.8198\n",
      "Epoch 42/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9469 - val_loss: -0.0181 - val_acc: 0.8131\n",
      "Epoch 43/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9489 - val_loss: -0.0181 - val_acc: 0.8120\n",
      "Epoch 44/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9477 - val_loss: -0.0182 - val_acc: 0.8220\n",
      "Epoch 45/45\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9483 - val_loss: -0.0181 - val_acc: 0.8142\n",
      "1928/2246 [========================>.....] - ETA: 0sTest score: -0.0179410055686\n",
      "Test accuracy: 0.813000890472\n"
     ]
    }
   ],
   "source": [
    "#Building model\n",
    "epochs=45\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='cosine_proximity',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "accuracy_epoch45=score[1]\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epochs為60次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0136 - acc: 0.6134 - val_loss: -0.0160 - val_acc: 0.7353\n",
      "Epoch 2/60\n",
      "8083/8083 [==============================] - 1s - loss: -0.0165 - acc: 0.7503 - val_loss: -0.0167 - val_acc: 0.7642\n",
      "Epoch 3/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0173 - acc: 0.7903 - val_loss: -0.0171 - val_acc: 0.7720\n",
      "Epoch 4/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0179 - acc: 0.8173 - val_loss: -0.0174 - val_acc: 0.7964\n",
      "Epoch 5/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0182 - acc: 0.8338 - val_loss: -0.0176 - val_acc: 0.7987\n",
      "Epoch 6/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0185 - acc: 0.8484 - val_loss: -0.0177 - val_acc: 0.7998\n",
      "Epoch 7/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0188 - acc: 0.8600 - val_loss: -0.0178 - val_acc: 0.8076\n",
      "Epoch 8/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0190 - acc: 0.8723 - val_loss: -0.0179 - val_acc: 0.8076\n",
      "Epoch 9/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0192 - acc: 0.8842 - val_loss: -0.0180 - val_acc: 0.8120\n",
      "Epoch 10/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0194 - acc: 0.8892 - val_loss: -0.0180 - val_acc: 0.8154\n",
      "Epoch 11/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0195 - acc: 0.8957 - val_loss: -0.0180 - val_acc: 0.8131\n",
      "Epoch 12/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0197 - acc: 0.9062 - val_loss: -0.0181 - val_acc: 0.8220\n",
      "Epoch 13/60\n",
      "8083/8083 [==============================] - 1s - loss: -0.0198 - acc: 0.9132 - val_loss: -0.0181 - val_acc: 0.8209\n",
      "Epoch 14/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0198 - acc: 0.9128 - val_loss: -0.0181 - val_acc: 0.8231\n",
      "Epoch 15/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0199 - acc: 0.9156 - val_loss: -0.0182 - val_acc: 0.8254\n",
      "Epoch 16/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0200 - acc: 0.9217 - val_loss: -0.0182 - val_acc: 0.8287\n",
      "Epoch 17/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0201 - acc: 0.9228 - val_loss: -0.0183 - val_acc: 0.8287\n",
      "Epoch 18/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0201 - acc: 0.9275 - val_loss: -0.0182 - val_acc: 0.8265\n",
      "Epoch 19/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0202 - acc: 0.9276 - val_loss: -0.0183 - val_acc: 0.8309\n",
      "Epoch 20/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0202 - acc: 0.9311 - val_loss: -0.0182 - val_acc: 0.8254\n",
      "Epoch 21/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0202 - acc: 0.9313 - val_loss: -0.0182 - val_acc: 0.8231\n",
      "Epoch 22/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0203 - acc: 0.9344 - val_loss: -0.0182 - val_acc: 0.8220\n",
      "Epoch 23/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0203 - acc: 0.9347 - val_loss: -0.0182 - val_acc: 0.8265\n",
      "Epoch 24/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0204 - acc: 0.9355 - val_loss: -0.0182 - val_acc: 0.8231\n",
      "Epoch 25/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0204 - acc: 0.9360 - val_loss: -0.0182 - val_acc: 0.8265\n",
      "Epoch 26/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0204 - acc: 0.9380 - val_loss: -0.0182 - val_acc: 0.8254\n",
      "Epoch 27/60\n",
      "8083/8083 [==============================] - 1s - loss: -0.0204 - acc: 0.9388 - val_loss: -0.0182 - val_acc: 0.8242\n",
      "Epoch 28/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0204 - acc: 0.9400 - val_loss: -0.0182 - val_acc: 0.8209\n",
      "Epoch 29/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0204 - acc: 0.9383 - val_loss: -0.0182 - val_acc: 0.8231\n",
      "Epoch 30/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0205 - acc: 0.9420 - val_loss: -0.0182 - val_acc: 0.8220\n",
      "Epoch 31/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0205 - acc: 0.9404 - val_loss: -0.0182 - val_acc: 0.8242\n",
      "Epoch 32/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0205 - acc: 0.9422 - val_loss: -0.0182 - val_acc: 0.8187\n",
      "Epoch 33/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0205 - acc: 0.9432 - val_loss: -0.0181 - val_acc: 0.8209\n",
      "Epoch 34/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0205 - acc: 0.9430 - val_loss: -0.0181 - val_acc: 0.8209\n",
      "Epoch 35/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0206 - acc: 0.9451 - val_loss: -0.0180 - val_acc: 0.8098\n",
      "Epoch 36/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0205 - acc: 0.9449 - val_loss: -0.0181 - val_acc: 0.8187\n",
      "Epoch 37/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0206 - acc: 0.9462 - val_loss: -0.0180 - val_acc: 0.8131\n",
      "Epoch 38/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0206 - acc: 0.9475 - val_loss: -0.0181 - val_acc: 0.8231\n",
      "Epoch 39/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0206 - acc: 0.9462 - val_loss: -0.0181 - val_acc: 0.8187\n",
      "Epoch 40/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0206 - acc: 0.9466 - val_loss: -0.0181 - val_acc: 0.8187\n",
      "Epoch 41/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0206 - acc: 0.9474 - val_loss: -0.0180 - val_acc: 0.8165\n",
      "Epoch 42/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0206 - acc: 0.9469 - val_loss: -0.0181 - val_acc: 0.8142\n",
      "Epoch 43/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0206 - acc: 0.9469 - val_loss: -0.0181 - val_acc: 0.8165\n",
      "Epoch 44/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0206 - acc: 0.9487 - val_loss: -0.0181 - val_acc: 0.8142\n",
      "Epoch 45/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0206 - acc: 0.9483 - val_loss: -0.0181 - val_acc: 0.8165\n",
      "Epoch 46/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0206 - acc: 0.9488 - val_loss: -0.0180 - val_acc: 0.8098\n",
      "Epoch 47/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0206 - acc: 0.9479 - val_loss: -0.0181 - val_acc: 0.8198\n",
      "Epoch 48/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0207 - acc: 0.9498 - val_loss: -0.0181 - val_acc: 0.8120\n",
      "Epoch 49/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0206 - acc: 0.9488 - val_loss: -0.0180 - val_acc: 0.8098\n",
      "Epoch 50/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0207 - acc: 0.9500 - val_loss: -0.0181 - val_acc: 0.8176\n",
      "Epoch 51/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0207 - acc: 0.9505 - val_loss: -0.0180 - val_acc: 0.8176\n",
      "Epoch 52/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0207 - acc: 0.9492 - val_loss: -0.0180 - val_acc: 0.8154\n",
      "Epoch 53/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0207 - acc: 0.9489 - val_loss: -0.0180 - val_acc: 0.8154\n",
      "Epoch 54/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0207 - acc: 0.9499 - val_loss: -0.0180 - val_acc: 0.8154\n",
      "Epoch 55/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0207 - acc: 0.9503 - val_loss: -0.0181 - val_acc: 0.8165\n",
      "Epoch 56/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0207 - acc: 0.9514 - val_loss: -0.0181 - val_acc: 0.8154\n",
      "Epoch 57/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0207 - acc: 0.9508 - val_loss: -0.0180 - val_acc: 0.8176\n",
      "Epoch 58/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0207 - acc: 0.9510 - val_loss: -0.0180 - val_acc: 0.8131\n",
      "Epoch 59/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0207 - acc: 0.9518 - val_loss: -0.0181 - val_acc: 0.8165\n",
      "Epoch 60/60\n",
      "8083/8083 [==============================] - 2s - loss: -0.0207 - acc: 0.9521 - val_loss: -0.0180 - val_acc: 0.8131\n",
      "1944/2246 [========================>.....] - ETA: 0sTest score: -0.0177900148456\n",
      "Test accuracy: 0.810329474675\n"
     ]
    }
   ],
   "source": [
    "#Building model\n",
    "epochs=60\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='cosine_proximity',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "accuracy_epoch60=score[1]\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epoch次數為75次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0137 - acc: 0.6143 - val_loss: -0.0159 - val_acc: 0.7219\n",
      "Epoch 2/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0165 - acc: 0.7538 - val_loss: -0.0167 - val_acc: 0.7620\n",
      "Epoch 3/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0173 - acc: 0.7898 - val_loss: -0.0171 - val_acc: 0.7709\n",
      "Epoch 4/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0179 - acc: 0.8167 - val_loss: -0.0174 - val_acc: 0.7964\n",
      "Epoch 5/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0182 - acc: 0.8320 - val_loss: -0.0175 - val_acc: 0.7909\n",
      "Epoch 6/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0186 - acc: 0.8510 - val_loss: -0.0177 - val_acc: 0.8020\n",
      "Epoch 7/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0188 - acc: 0.8596 - val_loss: -0.0177 - val_acc: 0.7998\n",
      "Epoch 8/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0190 - acc: 0.8742 - val_loss: -0.0179 - val_acc: 0.8098\n",
      "Epoch 9/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0192 - acc: 0.8807 - val_loss: -0.0179 - val_acc: 0.8176\n",
      "Epoch 10/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0194 - acc: 0.8904 - val_loss: -0.0181 - val_acc: 0.8176\n",
      "Epoch 11/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0196 - acc: 0.8998 - val_loss: -0.0180 - val_acc: 0.8154\n",
      "Epoch 12/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0196 - acc: 0.9023 - val_loss: -0.0181 - val_acc: 0.8198\n",
      "Epoch 13/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0198 - acc: 0.9078 - val_loss: -0.0182 - val_acc: 0.8265\n",
      "Epoch 14/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0199 - acc: 0.9135 - val_loss: -0.0182 - val_acc: 0.8298\n",
      "Epoch 15/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0199 - acc: 0.9145 - val_loss: -0.0181 - val_acc: 0.8120\n",
      "Epoch 16/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0200 - acc: 0.9198 - val_loss: -0.0182 - val_acc: 0.8276\n",
      "Epoch 17/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0201 - acc: 0.9222 - val_loss: -0.0182 - val_acc: 0.8287\n",
      "Epoch 18/75\n",
      "8083/8083 [==============================] - 2s - loss: -0.0201 - acc: 0.9240 - val_loss: -0.0182 - val_acc: 0.8231\n",
      "Epoch 19/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0202 - acc: 0.9281 - val_loss: -0.0182 - val_acc: 0.8209\n",
      "Epoch 20/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0202 - acc: 0.9322 - val_loss: -0.0182 - val_acc: 0.8187\n",
      "Epoch 21/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0203 - acc: 0.9326 - val_loss: -0.0182 - val_acc: 0.8254\n",
      "Epoch 22/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0203 - acc: 0.9333 - val_loss: -0.0182 - val_acc: 0.8242\n",
      "Epoch 23/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0203 - acc: 0.9364 - val_loss: -0.0183 - val_acc: 0.8231\n",
      "Epoch 24/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0204 - acc: 0.9365 - val_loss: -0.0182 - val_acc: 0.8242\n",
      "Epoch 25/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0204 - acc: 0.9380 - val_loss: -0.0182 - val_acc: 0.8209\n",
      "Epoch 26/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0204 - acc: 0.9396 - val_loss: -0.0181 - val_acc: 0.8165\n",
      "Epoch 27/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0204 - acc: 0.9409 - val_loss: -0.0181 - val_acc: 0.8187\n",
      "Epoch 28/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0205 - acc: 0.9425 - val_loss: -0.0181 - val_acc: 0.8120\n",
      "Epoch 29/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0205 - acc: 0.9417 - val_loss: -0.0181 - val_acc: 0.8198\n",
      "Epoch 30/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0205 - acc: 0.9438 - val_loss: -0.0181 - val_acc: 0.8187\n",
      "Epoch 31/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0205 - acc: 0.9428 - val_loss: -0.0181 - val_acc: 0.8154\n",
      "Epoch 32/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0205 - acc: 0.9433 - val_loss: -0.0181 - val_acc: 0.8098\n",
      "Epoch 33/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0205 - acc: 0.9438 - val_loss: -0.0181 - val_acc: 0.8209\n",
      "Epoch 34/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9452 - val_loss: -0.0182 - val_acc: 0.8187\n",
      "Epoch 35/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9454 - val_loss: -0.0181 - val_acc: 0.8187\n",
      "Epoch 36/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0205 - acc: 0.9445 - val_loss: -0.0182 - val_acc: 0.8187\n",
      "Epoch 37/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9448 - val_loss: -0.0181 - val_acc: 0.8142\n",
      "Epoch 38/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9470 - val_loss: -0.0181 - val_acc: 0.8131\n",
      "Epoch 39/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9466 - val_loss: -0.0181 - val_acc: 0.8165\n",
      "Epoch 40/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9477 - val_loss: -0.0182 - val_acc: 0.8209\n",
      "Epoch 41/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9478 - val_loss: -0.0181 - val_acc: 0.8209\n",
      "Epoch 42/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9485 - val_loss: -0.0181 - val_acc: 0.8154\n",
      "Epoch 43/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9482 - val_loss: -0.0180 - val_acc: 0.8165\n",
      "Epoch 44/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9489 - val_loss: -0.0181 - val_acc: 0.8154\n",
      "Epoch 45/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9484 - val_loss: -0.0181 - val_acc: 0.8187\n",
      "Epoch 46/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9494 - val_loss: -0.0181 - val_acc: 0.8131\n",
      "Epoch 47/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9498 - val_loss: -0.0181 - val_acc: 0.8165\n",
      "Epoch 48/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9490 - val_loss: -0.0179 - val_acc: 0.8131\n",
      "Epoch 49/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9509 - val_loss: -0.0180 - val_acc: 0.8098\n",
      "Epoch 50/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0206 - acc: 0.9479 - val_loss: -0.0180 - val_acc: 0.8087\n",
      "Epoch 51/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9510 - val_loss: -0.0181 - val_acc: 0.8109\n",
      "Epoch 52/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9511 - val_loss: -0.0180 - val_acc: 0.8109\n",
      "Epoch 53/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9504 - val_loss: -0.0181 - val_acc: 0.8142\n",
      "Epoch 54/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9500 - val_loss: -0.0180 - val_acc: 0.8098\n",
      "Epoch 55/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9510 - val_loss: -0.0180 - val_acc: 0.8076\n",
      "Epoch 56/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9511 - val_loss: -0.0180 - val_acc: 0.8065\n",
      "Epoch 57/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9513 - val_loss: -0.0180 - val_acc: 0.8087\n",
      "Epoch 58/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9511 - val_loss: -0.0180 - val_acc: 0.8087\n",
      "Epoch 59/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9516 - val_loss: -0.0180 - val_acc: 0.8109\n",
      "Epoch 60/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9501 - val_loss: -0.0180 - val_acc: 0.8154\n",
      "Epoch 61/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9530 - val_loss: -0.0180 - val_acc: 0.8120\n",
      "Epoch 62/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9535 - val_loss: -0.0181 - val_acc: 0.8120\n",
      "Epoch 63/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9534 - val_loss: -0.0180 - val_acc: 0.8098\n",
      "Epoch 64/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9529 - val_loss: -0.0179 - val_acc: 0.8109\n",
      "Epoch 65/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9514 - val_loss: -0.0180 - val_acc: 0.8120\n",
      "Epoch 66/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9521 - val_loss: -0.0180 - val_acc: 0.8076\n",
      "Epoch 67/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9535 - val_loss: -0.0180 - val_acc: 0.8087\n",
      "Epoch 68/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9525 - val_loss: -0.0180 - val_acc: 0.8154\n",
      "Epoch 69/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9522 - val_loss: -0.0179 - val_acc: 0.8098\n",
      "Epoch 70/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9525 - val_loss: -0.0180 - val_acc: 0.8087\n",
      "Epoch 71/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9522 - val_loss: -0.0180 - val_acc: 0.8098\n",
      "Epoch 72/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9529 - val_loss: -0.0180 - val_acc: 0.8098\n",
      "Epoch 73/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9529 - val_loss: -0.0179 - val_acc: 0.8020\n",
      "Epoch 74/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9539 - val_loss: -0.0180 - val_acc: 0.8131\n",
      "Epoch 75/75\n",
      "8083/8083 [==============================] - 1s - loss: -0.0207 - acc: 0.9525 - val_loss: -0.0179 - val_acc: 0.8053\n",
      "1920/2246 [========================>.....] - ETA: 0sTest score: -0.017793309806\n",
      "Test accuracy: 0.806767586821\n"
     ]
    }
   ],
   "source": [
    "#Building model\n",
    "epochs=75\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='cosine_proximity',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "accuracy_epoch75=score[1]\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs為15時，準確率為： 0.813000890525\n",
      "epochs為30時，準確率為： 0.8134461265\n",
      "epochs為45時，準確率為： 0.813000890472\n",
      "epochs為60時，準確率為： 0.810329474675\n",
      "epochs為75時，準確率為： 0.806767586821\n"
     ]
    }
   ],
   "source": [
    "print('epochs為15時，準確率為：',accuracy128)##epoch15\n",
    "print('epochs為30時，準確率為：',accuracy_epoch30)\n",
    "print('epochs為45時，準確率為：',accuracy_epoch45)\n",
    "print('epochs為60時，準確率為：',accuracy_epoch60)\n",
    "print('epochs為75時，準確率為：',accuracy_epoch75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
